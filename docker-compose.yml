version: "3.7"

services:

  zookeeper:
    image: confluentinc/cp-zookeeper:5.4.1
    container_name: zookeeper
    restart: unless-stopped
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      TZ: "${TZ-Europe/Berlin}"
    healthcheck:
      test: "echo stat | nc localhost $$ZOOKEEPER_CLIENT_PORT"
      start_period: 1m

  kafka:
    image: confluentinc/cp-kafka:5.4.1
    container_name: kafka
    restart: unless-stopped
    depends_on:
      - filebeat
      - zookeeper
    ports:
      - "29092:29092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      TZ: "${TZ-Europe/Berlin}"
    healthcheck:
      test: [ "CMD", "nc", "-z", "localhost", "9092" ]
      start_period: 1m

  kafka-rest-proxy:
    image: confluentinc/cp-kafka-rest:5.4.1
    container_name: kafka-rest-proxy
    restart: unless-stopped
    depends_on:
      - zookeeper
      - kafka
    ports:
      - "8082:8082"
    environment:
      KAFKA_REST_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:9092
      KAFKA_REST_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_REST_HOST_NAME: kafka-rest-proxy
      KAFKA_REST_LISTENERS: http://0.0.0.0:8082
      KAFKA_REST_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      KAFKA_REST_CONSUMER_REQUEST_TIMEOUT_MS: 30000
      TZ: "${TZ-Europe/Berlin}"
    healthcheck:
      test: "curl -f http://localhost:8082 || exit 1"
      start_period: 1m

  kafka-topics-ui:
    image: landoop/kafka-topics-ui:0.9.4
    container_name: kafka-topics-ui
    restart: unless-stopped
    depends_on:
      - kafka-rest-proxy
    ports:
      - "8085:8000"
    environment:
      KAFKA_REST_PROXY_URL: http://kafka-rest-proxy:8082
      PROXY: "true"
    healthcheck:
      test: "wget --quiet --tries=1 --spider http://localhost:8000 ||Â exit 1"
      start_period: 1m

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch-oss:6.4.2
    container_name: elasticsearch
    restart: unless-stopped
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      cluster.name: docker-es-cluster
      discovery.type: single-node
      bootstrap.memory_lock: "true"
      ES_JAVA_OPTS: "-Xms512m -Xmx512m"
    cap_add:
      - ALL
    privileged: true
    volumes:
      - esdata:/usr/share/elasticsearch/data
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test: "curl -f http://localhost:9200 || exit 1"
      start_period: 1m
    depends_on:
      - logstash

  zipkin:
    container_name: zipkin
    image: openzipkin/zipkin:2.20.2
    restart: unless-stopped
    ports:
      - "9411:9411"
    healthcheck:
      test: [ "CMD", "nc", "-z", "localhost", "9411" ]
      start_period: 1m

  kafka-manager:
    container_name: kafka-manager
    image: hlebalbau/kafka-manager:3.0.0.4
    restart: unless-stopped
    depends_on:
      - zookeeper
    ports:
      - "9000:9000"
    environment:
      ZK_HOSTS: zookeeper:2181
      APPLICATION_SECRET: "random-secret"
    command: -Dpidfile.path=/dev/null
    healthcheck:
      test: "curl -f http://localhost:9000 || exit 1"
      start_period: 1m


  logstash:
    image: docker.elastic.co/logstash/logstash:5.3.0
    container_name: logstash
    volumes:
      - ./logstash-config/config/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./logstash-config/pipeline:/usr/share/logstash/pipeline
    depends_on:
      - kafka

  kibana:
    image: docker.elastic.co/kibana/kibana-oss:6.4.2
    container_name: kibana
    environment:
      elasticsearch.url: http://localhost:9200
    depends_on:
      - elasticsearch
    ports:
      - "5601:5601"
    ulimits:
      nproc: 65535
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test: "curl -f http://localhost:5601 || exit 1"
      start_period: 1m
    cap_add:
      - ALL

  filebeat:
    hostname: filebeat
    user: root
    container_name: filebeat
    build:
      context: ./filebeat
    volumes:
      # needed to persist filebeat tracking data :
      - filebeat_data:/usr/share/filebeat/data:rw
      # needed to access all docker logs (read only) :
      - /var/lib/docker/containers:/usr/share/filebeat/dockerlogs/data:ro
      # needed to access additional informations about containers
      - /var/run/docker.sock:/var/run/docker.sock

volumes:
  # create a persistent volume for Filebeat
  filebeat_data:
  esdata: